{"ast":null,"code":"const {\n  deprecate\n} = require('util');\nconst byline = require('./byline');\nconst Index = require('./indexes.js');\nconst model = require('./model.js');\nconst storage = require('./storage.js');\nconst Waterfall = require('./waterfall.js');\nconst DEFAULT_DIR_MODE = 0o755;\nconst DEFAULT_FILE_MODE = 0o644;\n\n/**\n * Under the hood, NeDB's persistence uses an append-only format, meaning that all\n * updates and deletes actually result in lines added at the end of the datafile,\n * for performance reasons. The database is automatically compacted (i.e. put back\n * in the one-line-per-document format) every time you load each database within\n * your application.\n *\n * Persistence handles the compaction exposed in the Datastore {@link Datastore#compactDatafileAsync},\n * {@link Datastore#setAutocompactionInterval}.\n *\n * Since version 3.0.0, using {@link Datastore.persistence} methods manually is deprecated.\n *\n * Compaction takes a bit of time (not too much: 130ms for 50k\n * records on a typical development machine) and no other operation can happen when\n * it does, so most projects actually don't need to use it.\n *\n * Compaction will also immediately remove any documents whose data line has become\n * corrupted, assuming that the total percentage of all corrupted documents in that\n * database still falls below the specified `corruptAlertThreshold` option's value.\n *\n * Durability works similarly to major databases: compaction forces the OS to\n * physically flush data to disk, while appends to the data file do not (the OS is\n * responsible for flushing the data). That guarantees that a server crash can\n * never cause complete data loss, while preserving performance. The worst that can\n * happen is a crash between two syncs, causing a loss of all data between the two\n * syncs. Usually syncs are 30 seconds appart so that's at most 30 seconds of\n * data. [This post by Antirez on Redis persistence](http://oldblog.antirez.com/post/redis-persistence-demystified.html)\n * explains this in more details, NeDB being very close to Redis AOF persistence\n * with `appendfsync` option set to `no`.\n */\nclass Persistence {\n  /**\n   * Create a new Persistence object for database options.db\n   * @param {Datastore} options.db\n   * @param {Number} [options.corruptAlertThreshold] Optional, threshold after which an alert is thrown if too much data is corrupt\n   * @param {serializationHook} [options.beforeDeserialization] Hook you can use to transform data after it was serialized and before it is written to disk.\n   * @param {serializationHook} [options.afterSerialization] Inverse of `afterSerialization`.\n   * @param {object} [options.modes] Modes to use for FS permissions. Will not work on Windows.\n   * @param {number} [options.modes.fileMode=0o644] Mode to use for files.\n   * @param {number} [options.modes.dirMode=0o755] Mode to use for directories.\n   */\n  constructor(options) {\n    this.db = options.db;\n    this.inMemoryOnly = this.db.inMemoryOnly;\n    this.filename = this.db.filename;\n    this.corruptAlertThreshold = options.corruptAlertThreshold !== undefined ? options.corruptAlertThreshold : 0.1;\n    this.modes = options.modes !== undefined ? options.modes : {\n      fileMode: DEFAULT_FILE_MODE,\n      dirMode: DEFAULT_DIR_MODE\n    };\n    if (this.modes.fileMode === undefined) this.modes.fileMode = DEFAULT_FILE_MODE;\n    if (this.modes.dirMode === undefined) this.modes.dirMode = DEFAULT_DIR_MODE;\n    if (!this.inMemoryOnly && this.filename && this.filename.charAt(this.filename.length - 1) === '~') throw new Error('The datafile name can\\'t end with a ~, which is reserved for crash safe backup files');\n\n    // After serialization and before deserialization hooks with some basic sanity checks\n    if (options.afterSerialization && !options.beforeDeserialization) throw new Error('Serialization hook defined but deserialization hook undefined, cautiously refusing to start NeDB to prevent dataloss');\n    if (!options.afterSerialization && options.beforeDeserialization) throw new Error('Serialization hook undefined but deserialization hook defined, cautiously refusing to start NeDB to prevent dataloss');\n\n    // They are wrapped with an async function to ensure that if the hooks are synchronous they won't trigger an\n    // uncaught exception at runtime\n    this.afterSerialization = async s => (options.afterSerialization || (x => x))(s);\n    this.beforeDeserialization = async s => (options.beforeDeserialization || (x => x))(s);\n  }\n\n  /**\n   * Internal version without using the {@link Datastore#executor} of {@link Datastore#compactDatafileAsync}, use it instead.\n   * @return {Promise<void>}\n   * @private\n   */\n  async persistCachedDatabaseAsync() {\n    const lines = [];\n    if (this.inMemoryOnly) return;\n    for (const doc of this.db.getAllData()) {\n      lines.push(await this.afterSerialization(model.serialize(doc)));\n    }\n    for (const fieldName of Object.keys(this.db.indexes)) {\n      if (fieldName !== '_id') {\n        // The special _id index is managed by datastore.js, the others need to be persisted\n        lines.push(await this.afterSerialization(model.serialize({\n          $$indexCreated: {\n            fieldName: this.db.indexes[fieldName].fieldName,\n            unique: this.db.indexes[fieldName].unique,\n            sparse: this.db.indexes[fieldName].sparse\n          }\n        })));\n      }\n    }\n    await storage.crashSafeWriteFileLinesAsync(this.filename, lines, this.modes);\n    this.db.emit('compaction.done');\n  }\n\n  /**\n   * @see Datastore#compactDatafile\n   * @deprecated\n   * @param {NoParamCallback} [callback = () => {}]\n   * @see Persistence#compactDatafileAsync\n   */\n  compactDatafile(callback) {\n    deprecate(_callback => this.db.compactDatafile(_callback), '@seald-io/nedb: calling Datastore#persistence#compactDatafile is deprecated, please use Datastore#compactDatafile, it will be removed in the next major version.')(callback);\n  }\n\n  /**\n   * @see Datastore#setAutocompactionInterval\n   * @deprecated\n   */\n  setAutocompactionInterval(interval) {\n    deprecate(_interval => this.db.setAutocompactionInterval(_interval), '@seald-io/nedb: calling Datastore#persistence#setAutocompactionInterval is deprecated, please use Datastore#setAutocompactionInterval, it will be removed in the next major version.')(interval);\n  }\n\n  /**\n   * @see Datastore#stopAutocompaction\n   * @deprecated\n   */\n  stopAutocompaction() {\n    deprecate(() => this.db.stopAutocompaction(), '@seald-io/nedb: calling Datastore#persistence#stopAutocompaction is deprecated, please use Datastore#stopAutocompaction, it will be removed in the next major version.')();\n  }\n\n  /**\n   * Persist new state for the given newDocs (can be insertion, update or removal)\n   * Use an append-only format\n   *\n   * Do not use directly, it should only used by a {@link Datastore} instance.\n   * @param {document[]} newDocs Can be empty if no doc was updated/removed\n   * @return {Promise}\n   * @private\n   */\n  async persistNewStateAsync(newDocs) {\n    let toPersist = '';\n\n    // In-memory only datastore\n    if (this.inMemoryOnly) return;\n    for (const doc of newDocs) {\n      toPersist += (await this.afterSerialization(model.serialize(doc))) + '\\n';\n    }\n    if (toPersist.length === 0) return;\n    await storage.appendFileAsync(this.filename, toPersist, {\n      encoding: 'utf8',\n      mode: this.modes.fileMode\n    });\n  }\n\n  /**\n   * @typedef rawIndex\n   * @property {string} fieldName\n   * @property {boolean} [unique]\n   * @property {boolean} [sparse]\n   */\n\n  /**\n   * From a database's raw data, return the corresponding machine understandable collection.\n   *\n   * Do not use directly, it should only used by a {@link Datastore} instance.\n   * @param {string} rawData database file\n   * @return {{data: document[], indexes: Object.<string, rawIndex>}}\n   * @private\n   */\n  async treatRawData(rawData) {\n    const data = rawData.split('\\n').filter(datum => datum !== '').map(async datum => model.deserialize(await this.beforeDeserialization(datum)));\n    const dataById = {};\n    const indexes = {};\n    const dataLength = data.length;\n\n    // Last line of every data file is usually blank so not really corrupt\n    let corruptItems = 0;\n    for (const docToAwait of data) {\n      try {\n        const doc = await docToAwait;\n        if (doc._id) {\n          if (doc.$$deleted === true) delete dataById[doc._id];else dataById[doc._id] = doc;\n        } else if (doc.$$indexCreated && doc.$$indexCreated.fieldName != null) indexes[doc.$$indexCreated.fieldName] = doc.$$indexCreated;else if (typeof doc.$$indexRemoved === 'string') delete indexes[doc.$$indexRemoved];\n      } catch (e) {\n        corruptItems += 1;\n      }\n    }\n\n    // A bit lenient on corruption\n    if (dataLength > 0) {\n      const corruptionRate = corruptItems / dataLength;\n      if (corruptionRate > this.corruptAlertThreshold) {\n        const error = new Error(`${Math.floor(100 * corruptionRate)}% of the data file is corrupt, more than given corruptAlertThreshold (${Math.floor(100 * this.corruptAlertThreshold)}%). Cautiously refusing to start NeDB to prevent dataloss.`);\n        error.corruptionRate = corruptionRate;\n        error.corruptItems = corruptItems;\n        error.dataLength = dataLength;\n        throw error;\n      }\n    }\n    const tdata = Object.values(dataById);\n    return {\n      data: tdata,\n      indexes\n    };\n  }\n\n  /**\n   * From a database's raw data stream, return the corresponding machine understandable collection\n   * Is only used by a {@link Datastore} instance.\n   *\n   * Is only used in the Node.js version, since [React-Native]{@link module:storageReactNative} &\n   * [browser]{@link module:storageBrowser} storage modules don't provide an equivalent of\n   * {@link module:storage.readFileStream}.\n   *\n   * Do not use directly, it should only used by a {@link Datastore} instance.\n   * @param {Readable} rawStream\n   * @return {Promise<{data: document[], indexes: Object.<string, rawIndex>}>}\n   * @async\n   * @private\n   */\n  treatRawStreamAsync(rawStream) {\n    return new Promise((resolve, reject) => {\n      const dataById = {};\n      const indexes = {};\n      let corruptItems = 0;\n      const lineStream = byline(rawStream);\n      let dataLength = 0;\n      const waterfall = new Waterfall();\n      lineStream.on('data', line => {\n        const deserializedPromise = this.beforeDeserialization(line); // allows to run the deserialization hook in advance to optimize\n        return waterfall.waterfall(async () => {\n          // waterfall is used to preserve the order of lines\n          if (line === '') return;\n          try {\n            const doc = model.deserialize(await deserializedPromise);\n            if (doc._id) {\n              if (doc.$$deleted === true) delete dataById[doc._id];else dataById[doc._id] = doc;\n            } else if (doc.$$indexCreated && doc.$$indexCreated.fieldName != null) indexes[doc.$$indexCreated.fieldName] = doc.$$indexCreated;else if (typeof doc.$$indexRemoved === 'string') delete indexes[doc.$$indexRemoved];\n          } catch (e) {\n            corruptItems += 1;\n          }\n          dataLength++;\n        })();\n      });\n      lineStream.on('end', async () => {\n        await waterfall.guardian; // await the promises from the on('data') callbacks\n        // A bit lenient on corruption\n        if (dataLength > 0) {\n          const corruptionRate = corruptItems / dataLength;\n          if (corruptionRate > this.corruptAlertThreshold) {\n            const error = new Error(`${Math.floor(100 * corruptionRate)}% of the data file is corrupt, more than given corruptAlertThreshold (${Math.floor(100 * this.corruptAlertThreshold)}%). Cautiously refusing to start NeDB to prevent dataloss.`);\n            error.corruptionRate = corruptionRate;\n            error.corruptItems = corruptItems;\n            error.dataLength = dataLength;\n            reject(error, null);\n            return;\n          }\n        }\n        const data = Object.values(dataById);\n        resolve({\n          data,\n          indexes\n        });\n      });\n      lineStream.on('error', function (err) {\n        reject(err, null);\n      });\n    });\n  }\n\n  /**\n   * Load the database\n   * 1) Create all indexes\n   * 2) Insert all data\n   * 3) Compact the database\n   *\n   * This means pulling data out of the data file or creating it if it doesn't exist\n   * Also, all data is persisted right away, which has the effect of compacting the database file\n   * This operation is very quick at startup for a big collection (60ms for ~10k docs)\n   *\n   * Do not use directly as it does not use the [Executor]{@link Datastore.executor}, use {@link Datastore#loadDatabaseAsync} instead.\n   * @return {Promise<void>}\n   * @private\n   */\n  async loadDatabaseAsync() {\n    this.db._resetIndexes();\n\n    // In-memory only datastore\n    if (this.inMemoryOnly) return;\n    await Persistence.ensureParentDirectoryExistsAsync(this.filename, this.modes.dirMode);\n    await storage.ensureDatafileIntegrityAsync(this.filename, this.modes.fileMode);\n    let treatedData;\n    if (storage.readFileStream) {\n      // Server side\n      const fileStream = storage.readFileStream(this.filename, {\n        encoding: 'utf8',\n        mode: this.modes.fileMode\n      });\n      treatedData = await this.treatRawStreamAsync(fileStream);\n    } else {\n      // Browser\n      const rawData = await storage.readFileAsync(this.filename, {\n        encoding: 'utf8',\n        mode: this.modes.fileMode\n      });\n      treatedData = await this.treatRawData(rawData);\n    }\n    // Recreate all indexes in the datafile\n    Object.keys(treatedData.indexes).forEach(key => {\n      this.db.indexes[key] = new Index(treatedData.indexes[key]);\n    });\n\n    // Fill cached database (i.e. all indexes) with data\n    try {\n      this.db._resetIndexes(treatedData.data);\n    } catch (e) {\n      this.db._resetIndexes(); // Rollback any index which didn't fail\n      throw e;\n    }\n    await this.db.persistence.persistCachedDatabaseAsync();\n    this.db.executor.processBuffer();\n  }\n\n  /**\n   * See {@link Datastore#dropDatabaseAsync}. This function uses {@link Datastore#executor} internally. Decorating this\n   * function with an {@link Executor#pushAsync} will result in a deadlock.\n   * @return {Promise<void>}\n   * @private\n   * @see Datastore#dropDatabaseAsync\n   */\n  async dropDatabaseAsync() {\n    this.db.stopAutocompaction(); // stop autocompaction\n    this.db.executor.ready = false; // prevent queuing new tasks\n    this.db.executor.resetBuffer(); // remove pending buffered tasks\n    await this.db.executor.queue.guardian; // wait for the ongoing tasks to end\n    // remove indexes (which means remove data from memory)\n    this.db.indexes = {};\n    // add back _id index, otherwise it will fail\n    this.db.indexes._id = new Index({\n      fieldName: '_id',\n      unique: true\n    });\n    // reset TTL on indexes\n    this.db.ttlIndexes = {};\n\n    // remove datastore file\n    if (!this.db.inMemoryOnly) {\n      await this.db.executor.pushAsync(async () => {\n        if (await storage.existsAsync(this.filename)) await storage.unlinkAsync(this.filename);\n      }, true);\n    }\n  }\n\n  /**\n   * Check if a directory stat and create it on the fly if it is not the case.\n   * @param {string} dir\n   * @param {number} [mode=0o777]\n   * @return {Promise<void>}\n   * @private\n   */\n  static async ensureParentDirectoryExistsAsync(dir, mode = DEFAULT_DIR_MODE) {\n    return storage.ensureParentDirectoryExistsAsync(dir, mode);\n  }\n}\n\n// Interface\nmodule.exports = Persistence;","map":{"version":3,"names":["deprecate","require","byline","Index","model","storage","Waterfall","DEFAULT_DIR_MODE","DEFAULT_FILE_MODE","Persistence","constructor","options","db","inMemoryOnly","filename","corruptAlertThreshold","undefined","modes","fileMode","dirMode","charAt","length","Error","afterSerialization","beforeDeserialization","s","x","persistCachedDatabaseAsync","lines","doc","getAllData","push","serialize","fieldName","Object","keys","indexes","$$indexCreated","unique","sparse","crashSafeWriteFileLinesAsync","emit","compactDatafile","callback","_callback","setAutocompactionInterval","interval","_interval","stopAutocompaction","persistNewStateAsync","newDocs","toPersist","appendFileAsync","encoding","mode","treatRawData","rawData","data","split","filter","datum","map","deserialize","dataById","dataLength","corruptItems","docToAwait","_id","$$deleted","$$indexRemoved","e","corruptionRate","error","Math","floor","tdata","values","treatRawStreamAsync","rawStream","Promise","resolve","reject","lineStream","waterfall","on","line","deserializedPromise","guardian","err","loadDatabaseAsync","_resetIndexes","ensureParentDirectoryExistsAsync","ensureDatafileIntegrityAsync","treatedData","readFileStream","fileStream","readFileAsync","forEach","key","persistence","executor","processBuffer","dropDatabaseAsync","ready","resetBuffer","queue","ttlIndexes","pushAsync","existsAsync","unlinkAsync","dir","module","exports"],"sources":["C:/Users/benit/Music/arbisout/node_modules/@seald-io/nedb/lib/persistence.js"],"sourcesContent":["const { deprecate } = require('util')\nconst byline = require('./byline')\nconst Index = require('./indexes.js')\nconst model = require('./model.js')\nconst storage = require('./storage.js')\nconst Waterfall = require('./waterfall.js')\n\nconst DEFAULT_DIR_MODE = 0o755\nconst DEFAULT_FILE_MODE = 0o644\n\n/**\n * Under the hood, NeDB's persistence uses an append-only format, meaning that all\n * updates and deletes actually result in lines added at the end of the datafile,\n * for performance reasons. The database is automatically compacted (i.e. put back\n * in the one-line-per-document format) every time you load each database within\n * your application.\n *\n * Persistence handles the compaction exposed in the Datastore {@link Datastore#compactDatafileAsync},\n * {@link Datastore#setAutocompactionInterval}.\n *\n * Since version 3.0.0, using {@link Datastore.persistence} methods manually is deprecated.\n *\n * Compaction takes a bit of time (not too much: 130ms for 50k\n * records on a typical development machine) and no other operation can happen when\n * it does, so most projects actually don't need to use it.\n *\n * Compaction will also immediately remove any documents whose data line has become\n * corrupted, assuming that the total percentage of all corrupted documents in that\n * database still falls below the specified `corruptAlertThreshold` option's value.\n *\n * Durability works similarly to major databases: compaction forces the OS to\n * physically flush data to disk, while appends to the data file do not (the OS is\n * responsible for flushing the data). That guarantees that a server crash can\n * never cause complete data loss, while preserving performance. The worst that can\n * happen is a crash between two syncs, causing a loss of all data between the two\n * syncs. Usually syncs are 30 seconds appart so that's at most 30 seconds of\n * data. [This post by Antirez on Redis persistence](http://oldblog.antirez.com/post/redis-persistence-demystified.html)\n * explains this in more details, NeDB being very close to Redis AOF persistence\n * with `appendfsync` option set to `no`.\n */\nclass Persistence {\n  /**\n   * Create a new Persistence object for database options.db\n   * @param {Datastore} options.db\n   * @param {Number} [options.corruptAlertThreshold] Optional, threshold after which an alert is thrown if too much data is corrupt\n   * @param {serializationHook} [options.beforeDeserialization] Hook you can use to transform data after it was serialized and before it is written to disk.\n   * @param {serializationHook} [options.afterSerialization] Inverse of `afterSerialization`.\n   * @param {object} [options.modes] Modes to use for FS permissions. Will not work on Windows.\n   * @param {number} [options.modes.fileMode=0o644] Mode to use for files.\n   * @param {number} [options.modes.dirMode=0o755] Mode to use for directories.\n   */\n  constructor (options) {\n    this.db = options.db\n    this.inMemoryOnly = this.db.inMemoryOnly\n    this.filename = this.db.filename\n    this.corruptAlertThreshold = options.corruptAlertThreshold !== undefined ? options.corruptAlertThreshold : 0.1\n    this.modes = options.modes !== undefined\n      ? options.modes\n      : {\n          fileMode: DEFAULT_FILE_MODE,\n          dirMode: DEFAULT_DIR_MODE\n        }\n    if (this.modes.fileMode === undefined) this.modes.fileMode = DEFAULT_FILE_MODE\n    if (this.modes.dirMode === undefined) this.modes.dirMode = DEFAULT_DIR_MODE\n    if (\n      !this.inMemoryOnly &&\n      this.filename &&\n      this.filename.charAt(this.filename.length - 1) === '~'\n    ) throw new Error('The datafile name can\\'t end with a ~, which is reserved for crash safe backup files')\n\n    // After serialization and before deserialization hooks with some basic sanity checks\n    if (\n      options.afterSerialization &&\n      !options.beforeDeserialization\n    ) throw new Error('Serialization hook defined but deserialization hook undefined, cautiously refusing to start NeDB to prevent dataloss')\n    if (\n      !options.afterSerialization &&\n      options.beforeDeserialization\n    ) throw new Error('Serialization hook undefined but deserialization hook defined, cautiously refusing to start NeDB to prevent dataloss')\n\n    // They are wrapped with an async function to ensure that if the hooks are synchronous they won't trigger an\n    // uncaught exception at runtime\n    this.afterSerialization = async (s) => (options.afterSerialization || (x => x))(s)\n    this.beforeDeserialization = async (s) => (options.beforeDeserialization || (x => x))(s)\n  }\n\n  /**\n   * Internal version without using the {@link Datastore#executor} of {@link Datastore#compactDatafileAsync}, use it instead.\n   * @return {Promise<void>}\n   * @private\n   */\n  async persistCachedDatabaseAsync () {\n    const lines = []\n\n    if (this.inMemoryOnly) return\n\n    for (const doc of this.db.getAllData()) {\n      lines.push(await this.afterSerialization(model.serialize(doc)))\n    }\n    for (const fieldName of Object.keys(this.db.indexes)) {\n      if (fieldName !== '_id') { // The special _id index is managed by datastore.js, the others need to be persisted\n        lines.push(await this.afterSerialization(model.serialize({\n          $$indexCreated: {\n            fieldName: this.db.indexes[fieldName].fieldName,\n            unique: this.db.indexes[fieldName].unique,\n            sparse: this.db.indexes[fieldName].sparse\n          }\n        })))\n      }\n    }\n\n    await storage.crashSafeWriteFileLinesAsync(this.filename, lines, this.modes)\n    this.db.emit('compaction.done')\n  }\n\n  /**\n   * @see Datastore#compactDatafile\n   * @deprecated\n   * @param {NoParamCallback} [callback = () => {}]\n   * @see Persistence#compactDatafileAsync\n   */\n  compactDatafile (callback) {\n    deprecate(_callback => this.db.compactDatafile(_callback), '@seald-io/nedb: calling Datastore#persistence#compactDatafile is deprecated, please use Datastore#compactDatafile, it will be removed in the next major version.')(callback)\n  }\n\n  /**\n   * @see Datastore#setAutocompactionInterval\n   * @deprecated\n   */\n  setAutocompactionInterval (interval) {\n    deprecate(_interval => this.db.setAutocompactionInterval(_interval), '@seald-io/nedb: calling Datastore#persistence#setAutocompactionInterval is deprecated, please use Datastore#setAutocompactionInterval, it will be removed in the next major version.')(interval)\n  }\n\n  /**\n   * @see Datastore#stopAutocompaction\n   * @deprecated\n   */\n  stopAutocompaction () {\n    deprecate(() => this.db.stopAutocompaction(), '@seald-io/nedb: calling Datastore#persistence#stopAutocompaction is deprecated, please use Datastore#stopAutocompaction, it will be removed in the next major version.')()\n  }\n\n  /**\n   * Persist new state for the given newDocs (can be insertion, update or removal)\n   * Use an append-only format\n   *\n   * Do not use directly, it should only used by a {@link Datastore} instance.\n   * @param {document[]} newDocs Can be empty if no doc was updated/removed\n   * @return {Promise}\n   * @private\n   */\n  async persistNewStateAsync (newDocs) {\n    let toPersist = ''\n\n    // In-memory only datastore\n    if (this.inMemoryOnly) return\n\n    for (const doc of newDocs) {\n      toPersist += await this.afterSerialization(model.serialize(doc)) + '\\n'\n    }\n\n    if (toPersist.length === 0) return\n\n    await storage.appendFileAsync(this.filename, toPersist, { encoding: 'utf8', mode: this.modes.fileMode })\n  }\n\n  /**\n   * @typedef rawIndex\n   * @property {string} fieldName\n   * @property {boolean} [unique]\n   * @property {boolean} [sparse]\n   */\n\n  /**\n   * From a database's raw data, return the corresponding machine understandable collection.\n   *\n   * Do not use directly, it should only used by a {@link Datastore} instance.\n   * @param {string} rawData database file\n   * @return {{data: document[], indexes: Object.<string, rawIndex>}}\n   * @private\n   */\n  async treatRawData (rawData) {\n    const data = rawData\n      .split('\\n')\n      .filter(datum => datum !== '')\n      .map(async datum => model.deserialize(await this.beforeDeserialization(datum)))\n    const dataById = {}\n    const indexes = {}\n    const dataLength = data.length\n\n    // Last line of every data file is usually blank so not really corrupt\n    let corruptItems = 0\n\n    for (const docToAwait of data) {\n      try {\n        const doc = await docToAwait\n        if (doc._id) {\n          if (doc.$$deleted === true) delete dataById[doc._id]\n          else dataById[doc._id] = doc\n        } else if (doc.$$indexCreated && doc.$$indexCreated.fieldName != null) indexes[doc.$$indexCreated.fieldName] = doc.$$indexCreated\n        else if (typeof doc.$$indexRemoved === 'string') delete indexes[doc.$$indexRemoved]\n      } catch (e) {\n        corruptItems += 1\n      }\n    }\n\n    // A bit lenient on corruption\n    if (dataLength > 0) {\n      const corruptionRate = corruptItems / dataLength\n      if (corruptionRate > this.corruptAlertThreshold) {\n        const error = new Error(`${Math.floor(100 * corruptionRate)}% of the data file is corrupt, more than given corruptAlertThreshold (${Math.floor(100 * this.corruptAlertThreshold)}%). Cautiously refusing to start NeDB to prevent dataloss.`)\n        error.corruptionRate = corruptionRate\n        error.corruptItems = corruptItems\n        error.dataLength = dataLength\n        throw error\n      }\n    }\n\n    const tdata = Object.values(dataById)\n\n    return { data: tdata, indexes }\n  }\n\n  /**\n   * From a database's raw data stream, return the corresponding machine understandable collection\n   * Is only used by a {@link Datastore} instance.\n   *\n   * Is only used in the Node.js version, since [React-Native]{@link module:storageReactNative} &\n   * [browser]{@link module:storageBrowser} storage modules don't provide an equivalent of\n   * {@link module:storage.readFileStream}.\n   *\n   * Do not use directly, it should only used by a {@link Datastore} instance.\n   * @param {Readable} rawStream\n   * @return {Promise<{data: document[], indexes: Object.<string, rawIndex>}>}\n   * @async\n   * @private\n   */\n  treatRawStreamAsync (rawStream) {\n    return new Promise((resolve, reject) => {\n      const dataById = {}\n\n      const indexes = {}\n\n      let corruptItems = 0\n\n      const lineStream = byline(rawStream)\n      let dataLength = 0\n\n      const waterfall = new Waterfall()\n\n      lineStream.on('data', (line) => {\n        const deserializedPromise = this.beforeDeserialization(line) // allows to run the deserialization hook in advance to optimize\n        return waterfall.waterfall(async () => { // waterfall is used to preserve the order of lines\n          if (line === '') return\n          try {\n            const doc = model.deserialize(await deserializedPromise)\n            if (doc._id) {\n              if (doc.$$deleted === true) delete dataById[doc._id]\n              else dataById[doc._id] = doc\n            } else if (doc.$$indexCreated && doc.$$indexCreated.fieldName != null) indexes[doc.$$indexCreated.fieldName] = doc.$$indexCreated\n            else if (typeof doc.$$indexRemoved === 'string') delete indexes[doc.$$indexRemoved]\n          } catch (e) {\n            corruptItems += 1\n          }\n\n          dataLength++\n        })()\n      })\n\n      lineStream.on('end', async () => {\n        await waterfall.guardian // await the promises from the on('data') callbacks\n        // A bit lenient on corruption\n        if (dataLength > 0) {\n          const corruptionRate = corruptItems / dataLength\n          if (corruptionRate > this.corruptAlertThreshold) {\n            const error = new Error(`${Math.floor(100 * corruptionRate)}% of the data file is corrupt, more than given corruptAlertThreshold (${Math.floor(100 * this.corruptAlertThreshold)}%). Cautiously refusing to start NeDB to prevent dataloss.`)\n            error.corruptionRate = corruptionRate\n            error.corruptItems = corruptItems\n            error.dataLength = dataLength\n            reject(error, null)\n            return\n          }\n        }\n        const data = Object.values(dataById)\n\n        resolve({ data, indexes })\n      })\n\n      lineStream.on('error', function (err) {\n        reject(err, null)\n      })\n    })\n  }\n\n  /**\n   * Load the database\n   * 1) Create all indexes\n   * 2) Insert all data\n   * 3) Compact the database\n   *\n   * This means pulling data out of the data file or creating it if it doesn't exist\n   * Also, all data is persisted right away, which has the effect of compacting the database file\n   * This operation is very quick at startup for a big collection (60ms for ~10k docs)\n   *\n   * Do not use directly as it does not use the [Executor]{@link Datastore.executor}, use {@link Datastore#loadDatabaseAsync} instead.\n   * @return {Promise<void>}\n   * @private\n   */\n  async loadDatabaseAsync () {\n    this.db._resetIndexes()\n\n    // In-memory only datastore\n    if (this.inMemoryOnly) return\n    await Persistence.ensureParentDirectoryExistsAsync(this.filename, this.modes.dirMode)\n    await storage.ensureDatafileIntegrityAsync(this.filename, this.modes.fileMode)\n\n    let treatedData\n    if (storage.readFileStream) {\n      // Server side\n      const fileStream = storage.readFileStream(this.filename, { encoding: 'utf8', mode: this.modes.fileMode })\n      treatedData = await this.treatRawStreamAsync(fileStream)\n    } else {\n      // Browser\n      const rawData = await storage.readFileAsync(this.filename, { encoding: 'utf8', mode: this.modes.fileMode })\n      treatedData = await this.treatRawData(rawData)\n    }\n    // Recreate all indexes in the datafile\n    Object.keys(treatedData.indexes).forEach(key => {\n      this.db.indexes[key] = new Index(treatedData.indexes[key])\n    })\n\n    // Fill cached database (i.e. all indexes) with data\n    try {\n      this.db._resetIndexes(treatedData.data)\n    } catch (e) {\n      this.db._resetIndexes() // Rollback any index which didn't fail\n      throw e\n    }\n\n    await this.db.persistence.persistCachedDatabaseAsync()\n    this.db.executor.processBuffer()\n  }\n\n  /**\n   * See {@link Datastore#dropDatabaseAsync}. This function uses {@link Datastore#executor} internally. Decorating this\n   * function with an {@link Executor#pushAsync} will result in a deadlock.\n   * @return {Promise<void>}\n   * @private\n   * @see Datastore#dropDatabaseAsync\n   */\n  async dropDatabaseAsync () {\n    this.db.stopAutocompaction() // stop autocompaction\n    this.db.executor.ready = false // prevent queuing new tasks\n    this.db.executor.resetBuffer() // remove pending buffered tasks\n    await this.db.executor.queue.guardian // wait for the ongoing tasks to end\n    // remove indexes (which means remove data from memory)\n    this.db.indexes = {}\n    // add back _id index, otherwise it will fail\n    this.db.indexes._id = new Index({ fieldName: '_id', unique: true })\n    // reset TTL on indexes\n    this.db.ttlIndexes = {}\n\n    // remove datastore file\n    if (!this.db.inMemoryOnly) {\n      await this.db.executor.pushAsync(async () => {\n        if (await storage.existsAsync(this.filename)) await storage.unlinkAsync(this.filename)\n      }, true)\n    }\n  }\n\n  /**\n   * Check if a directory stat and create it on the fly if it is not the case.\n   * @param {string} dir\n   * @param {number} [mode=0o777]\n   * @return {Promise<void>}\n   * @private\n   */\n  static async ensureParentDirectoryExistsAsync (dir, mode = DEFAULT_DIR_MODE) {\n    return storage.ensureParentDirectoryExistsAsync(dir, mode)\n  }\n}\n\n// Interface\nmodule.exports = Persistence\n"],"mappings":"AAAA,MAAM;EAAEA;AAAU,CAAC,GAAGC,OAAO,CAAC,MAAM,CAAC;AACrC,MAAMC,MAAM,GAAGD,OAAO,CAAC,UAAU,CAAC;AAClC,MAAME,KAAK,GAAGF,OAAO,CAAC,cAAc,CAAC;AACrC,MAAMG,KAAK,GAAGH,OAAO,CAAC,YAAY,CAAC;AACnC,MAAMI,OAAO,GAAGJ,OAAO,CAAC,cAAc,CAAC;AACvC,MAAMK,SAAS,GAAGL,OAAO,CAAC,gBAAgB,CAAC;AAE3C,MAAMM,gBAAgB,GAAG,KAAK;AAC9B,MAAMC,iBAAiB,GAAG,KAAK;;AAE/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAMC,WAAW,CAAC;EAChB;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACEC,WAAWA,CAAEC,OAAO,EAAE;IACpB,IAAI,CAACC,EAAE,GAAGD,OAAO,CAACC,EAAE;IACpB,IAAI,CAACC,YAAY,GAAG,IAAI,CAACD,EAAE,CAACC,YAAY;IACxC,IAAI,CAACC,QAAQ,GAAG,IAAI,CAACF,EAAE,CAACE,QAAQ;IAChC,IAAI,CAACC,qBAAqB,GAAGJ,OAAO,CAACI,qBAAqB,KAAKC,SAAS,GAAGL,OAAO,CAACI,qBAAqB,GAAG,GAAG;IAC9G,IAAI,CAACE,KAAK,GAAGN,OAAO,CAACM,KAAK,KAAKD,SAAS,GACpCL,OAAO,CAACM,KAAK,GACb;MACEC,QAAQ,EAAEV,iBAAiB;MAC3BW,OAAO,EAAEZ;IACX,CAAC;IACL,IAAI,IAAI,CAACU,KAAK,CAACC,QAAQ,KAAKF,SAAS,EAAE,IAAI,CAACC,KAAK,CAACC,QAAQ,GAAGV,iBAAiB;IAC9E,IAAI,IAAI,CAACS,KAAK,CAACE,OAAO,KAAKH,SAAS,EAAE,IAAI,CAACC,KAAK,CAACE,OAAO,GAAGZ,gBAAgB;IAC3E,IACE,CAAC,IAAI,CAACM,YAAY,IAClB,IAAI,CAACC,QAAQ,IACb,IAAI,CAACA,QAAQ,CAACM,MAAM,CAAC,IAAI,CAACN,QAAQ,CAACO,MAAM,GAAG,CAAC,CAAC,KAAK,GAAG,EACtD,MAAM,IAAIC,KAAK,CAAC,sFAAsF,CAAC;;IAEzG;IACA,IACEX,OAAO,CAACY,kBAAkB,IAC1B,CAACZ,OAAO,CAACa,qBAAqB,EAC9B,MAAM,IAAIF,KAAK,CAAC,sHAAsH,CAAC;IACzI,IACE,CAACX,OAAO,CAACY,kBAAkB,IAC3BZ,OAAO,CAACa,qBAAqB,EAC7B,MAAM,IAAIF,KAAK,CAAC,sHAAsH,CAAC;;IAEzI;IACA;IACA,IAAI,CAACC,kBAAkB,GAAG,MAAOE,CAAC,IAAK,CAACd,OAAO,CAACY,kBAAkB,KAAKG,CAAC,IAAIA,CAAC,CAAC,EAAED,CAAC,CAAC;IAClF,IAAI,CAACD,qBAAqB,GAAG,MAAOC,CAAC,IAAK,CAACd,OAAO,CAACa,qBAAqB,KAAKE,CAAC,IAAIA,CAAC,CAAC,EAAED,CAAC,CAAC;EAC1F;;EAEA;AACF;AACA;AACA;AACA;EACE,MAAME,0BAA0BA,CAAA,EAAI;IAClC,MAAMC,KAAK,GAAG,EAAE;IAEhB,IAAI,IAAI,CAACf,YAAY,EAAE;IAEvB,KAAK,MAAMgB,GAAG,IAAI,IAAI,CAACjB,EAAE,CAACkB,UAAU,CAAC,CAAC,EAAE;MACtCF,KAAK,CAACG,IAAI,CAAC,MAAM,IAAI,CAACR,kBAAkB,CAACnB,KAAK,CAAC4B,SAAS,CAACH,GAAG,CAAC,CAAC,CAAC;IACjE;IACA,KAAK,MAAMI,SAAS,IAAIC,MAAM,CAACC,IAAI,CAAC,IAAI,CAACvB,EAAE,CAACwB,OAAO,CAAC,EAAE;MACpD,IAAIH,SAAS,KAAK,KAAK,EAAE;QAAE;QACzBL,KAAK,CAACG,IAAI,CAAC,MAAM,IAAI,CAACR,kBAAkB,CAACnB,KAAK,CAAC4B,SAAS,CAAC;UACvDK,cAAc,EAAE;YACdJ,SAAS,EAAE,IAAI,CAACrB,EAAE,CAACwB,OAAO,CAACH,SAAS,CAAC,CAACA,SAAS;YAC/CK,MAAM,EAAE,IAAI,CAAC1B,EAAE,CAACwB,OAAO,CAACH,SAAS,CAAC,CAACK,MAAM;YACzCC,MAAM,EAAE,IAAI,CAAC3B,EAAE,CAACwB,OAAO,CAACH,SAAS,CAAC,CAACM;UACrC;QACF,CAAC,CAAC,CAAC,CAAC;MACN;IACF;IAEA,MAAMlC,OAAO,CAACmC,4BAA4B,CAAC,IAAI,CAAC1B,QAAQ,EAAEc,KAAK,EAAE,IAAI,CAACX,KAAK,CAAC;IAC5E,IAAI,CAACL,EAAE,CAAC6B,IAAI,CAAC,iBAAiB,CAAC;EACjC;;EAEA;AACF;AACA;AACA;AACA;AACA;EACEC,eAAeA,CAAEC,QAAQ,EAAE;IACzB3C,SAAS,CAAC4C,SAAS,IAAI,IAAI,CAAChC,EAAE,CAAC8B,eAAe,CAACE,SAAS,CAAC,EAAE,kKAAkK,CAAC,CAACD,QAAQ,CAAC;EAC1O;;EAEA;AACF;AACA;AACA;EACEE,yBAAyBA,CAAEC,QAAQ,EAAE;IACnC9C,SAAS,CAAC+C,SAAS,IAAI,IAAI,CAACnC,EAAE,CAACiC,yBAAyB,CAACE,SAAS,CAAC,EAAE,sLAAsL,CAAC,CAACD,QAAQ,CAAC;EACxQ;;EAEA;AACF;AACA;AACA;EACEE,kBAAkBA,CAAA,EAAI;IACpBhD,SAAS,CAAC,MAAM,IAAI,CAACY,EAAE,CAACoC,kBAAkB,CAAC,CAAC,EAAE,wKAAwK,CAAC,CAAC,CAAC;EAC3N;;EAEA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,MAAMC,oBAAoBA,CAAEC,OAAO,EAAE;IACnC,IAAIC,SAAS,GAAG,EAAE;;IAElB;IACA,IAAI,IAAI,CAACtC,YAAY,EAAE;IAEvB,KAAK,MAAMgB,GAAG,IAAIqB,OAAO,EAAE;MACzBC,SAAS,IAAI,OAAM,IAAI,CAAC5B,kBAAkB,CAACnB,KAAK,CAAC4B,SAAS,CAACH,GAAG,CAAC,CAAC,IAAG,IAAI;IACzE;IAEA,IAAIsB,SAAS,CAAC9B,MAAM,KAAK,CAAC,EAAE;IAE5B,MAAMhB,OAAO,CAAC+C,eAAe,CAAC,IAAI,CAACtC,QAAQ,EAAEqC,SAAS,EAAE;MAAEE,QAAQ,EAAE,MAAM;MAAEC,IAAI,EAAE,IAAI,CAACrC,KAAK,CAACC;IAAS,CAAC,CAAC;EAC1G;;EAEA;AACF;AACA;AACA;AACA;AACA;;EAEE;AACF;AACA;AACA;AACA;AACA;AACA;AACA;EACE,MAAMqC,YAAYA,CAAEC,OAAO,EAAE;IAC3B,MAAMC,IAAI,GAAGD,OAAO,CACjBE,KAAK,CAAC,IAAI,CAAC,CACXC,MAAM,CAACC,KAAK,IAAIA,KAAK,KAAK,EAAE,CAAC,CAC7BC,GAAG,CAAC,MAAMD,KAAK,IAAIxD,KAAK,CAAC0D,WAAW,CAAC,MAAM,IAAI,CAACtC,qBAAqB,CAACoC,KAAK,CAAC,CAAC,CAAC;IACjF,MAAMG,QAAQ,GAAG,CAAC,CAAC;IACnB,MAAM3B,OAAO,GAAG,CAAC,CAAC;IAClB,MAAM4B,UAAU,GAAGP,IAAI,CAACpC,MAAM;;IAE9B;IACA,IAAI4C,YAAY,GAAG,CAAC;IAEpB,KAAK,MAAMC,UAAU,IAAIT,IAAI,EAAE;MAC7B,IAAI;QACF,MAAM5B,GAAG,GAAG,MAAMqC,UAAU;QAC5B,IAAIrC,GAAG,CAACsC,GAAG,EAAE;UACX,IAAItC,GAAG,CAACuC,SAAS,KAAK,IAAI,EAAE,OAAOL,QAAQ,CAAClC,GAAG,CAACsC,GAAG,CAAC,MAC/CJ,QAAQ,CAAClC,GAAG,CAACsC,GAAG,CAAC,GAAGtC,GAAG;QAC9B,CAAC,MAAM,IAAIA,GAAG,CAACQ,cAAc,IAAIR,GAAG,CAACQ,cAAc,CAACJ,SAAS,IAAI,IAAI,EAAEG,OAAO,CAACP,GAAG,CAACQ,cAAc,CAACJ,SAAS,CAAC,GAAGJ,GAAG,CAACQ,cAAc,MAC5H,IAAI,OAAOR,GAAG,CAACwC,cAAc,KAAK,QAAQ,EAAE,OAAOjC,OAAO,CAACP,GAAG,CAACwC,cAAc,CAAC;MACrF,CAAC,CAAC,OAAOC,CAAC,EAAE;QACVL,YAAY,IAAI,CAAC;MACnB;IACF;;IAEA;IACA,IAAID,UAAU,GAAG,CAAC,EAAE;MAClB,MAAMO,cAAc,GAAGN,YAAY,GAAGD,UAAU;MAChD,IAAIO,cAAc,GAAG,IAAI,CAACxD,qBAAqB,EAAE;QAC/C,MAAMyD,KAAK,GAAG,IAAIlD,KAAK,CAAC,GAAGmD,IAAI,CAACC,KAAK,CAAC,GAAG,GAAGH,cAAc,CAAC,yEAAyEE,IAAI,CAACC,KAAK,CAAC,GAAG,GAAG,IAAI,CAAC3D,qBAAqB,CAAC,4DAA4D,CAAC;QAC7OyD,KAAK,CAACD,cAAc,GAAGA,cAAc;QACrCC,KAAK,CAACP,YAAY,GAAGA,YAAY;QACjCO,KAAK,CAACR,UAAU,GAAGA,UAAU;QAC7B,MAAMQ,KAAK;MACb;IACF;IAEA,MAAMG,KAAK,GAAGzC,MAAM,CAAC0C,MAAM,CAACb,QAAQ,CAAC;IAErC,OAAO;MAAEN,IAAI,EAAEkB,KAAK;MAAEvC;IAAQ,CAAC;EACjC;;EAEA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACEyC,mBAAmBA,CAAEC,SAAS,EAAE;IAC9B,OAAO,IAAIC,OAAO,CAAC,CAACC,OAAO,EAAEC,MAAM,KAAK;MACtC,MAAMlB,QAAQ,GAAG,CAAC,CAAC;MAEnB,MAAM3B,OAAO,GAAG,CAAC,CAAC;MAElB,IAAI6B,YAAY,GAAG,CAAC;MAEpB,MAAMiB,UAAU,GAAGhF,MAAM,CAAC4E,SAAS,CAAC;MACpC,IAAId,UAAU,GAAG,CAAC;MAElB,MAAMmB,SAAS,GAAG,IAAI7E,SAAS,CAAC,CAAC;MAEjC4E,UAAU,CAACE,EAAE,CAAC,MAAM,EAAGC,IAAI,IAAK;QAC9B,MAAMC,mBAAmB,GAAG,IAAI,CAAC9D,qBAAqB,CAAC6D,IAAI,CAAC,EAAC;QAC7D,OAAOF,SAAS,CAACA,SAAS,CAAC,YAAY;UAAE;UACvC,IAAIE,IAAI,KAAK,EAAE,EAAE;UACjB,IAAI;YACF,MAAMxD,GAAG,GAAGzB,KAAK,CAAC0D,WAAW,CAAC,MAAMwB,mBAAmB,CAAC;YACxD,IAAIzD,GAAG,CAACsC,GAAG,EAAE;cACX,IAAItC,GAAG,CAACuC,SAAS,KAAK,IAAI,EAAE,OAAOL,QAAQ,CAAClC,GAAG,CAACsC,GAAG,CAAC,MAC/CJ,QAAQ,CAAClC,GAAG,CAACsC,GAAG,CAAC,GAAGtC,GAAG;YAC9B,CAAC,MAAM,IAAIA,GAAG,CAACQ,cAAc,IAAIR,GAAG,CAACQ,cAAc,CAACJ,SAAS,IAAI,IAAI,EAAEG,OAAO,CAACP,GAAG,CAACQ,cAAc,CAACJ,SAAS,CAAC,GAAGJ,GAAG,CAACQ,cAAc,MAC5H,IAAI,OAAOR,GAAG,CAACwC,cAAc,KAAK,QAAQ,EAAE,OAAOjC,OAAO,CAACP,GAAG,CAACwC,cAAc,CAAC;UACrF,CAAC,CAAC,OAAOC,CAAC,EAAE;YACVL,YAAY,IAAI,CAAC;UACnB;UAEAD,UAAU,EAAE;QACd,CAAC,CAAC,CAAC,CAAC;MACN,CAAC,CAAC;MAEFkB,UAAU,CAACE,EAAE,CAAC,KAAK,EAAE,YAAY;QAC/B,MAAMD,SAAS,CAACI,QAAQ,EAAC;QACzB;QACA,IAAIvB,UAAU,GAAG,CAAC,EAAE;UAClB,MAAMO,cAAc,GAAGN,YAAY,GAAGD,UAAU;UAChD,IAAIO,cAAc,GAAG,IAAI,CAACxD,qBAAqB,EAAE;YAC/C,MAAMyD,KAAK,GAAG,IAAIlD,KAAK,CAAC,GAAGmD,IAAI,CAACC,KAAK,CAAC,GAAG,GAAGH,cAAc,CAAC,yEAAyEE,IAAI,CAACC,KAAK,CAAC,GAAG,GAAG,IAAI,CAAC3D,qBAAqB,CAAC,4DAA4D,CAAC;YAC7OyD,KAAK,CAACD,cAAc,GAAGA,cAAc;YACrCC,KAAK,CAACP,YAAY,GAAGA,YAAY;YACjCO,KAAK,CAACR,UAAU,GAAGA,UAAU;YAC7BiB,MAAM,CAACT,KAAK,EAAE,IAAI,CAAC;YACnB;UACF;QACF;QACA,MAAMf,IAAI,GAAGvB,MAAM,CAAC0C,MAAM,CAACb,QAAQ,CAAC;QAEpCiB,OAAO,CAAC;UAAEvB,IAAI;UAAErB;QAAQ,CAAC,CAAC;MAC5B,CAAC,CAAC;MAEF8C,UAAU,CAACE,EAAE,CAAC,OAAO,EAAE,UAAUI,GAAG,EAAE;QACpCP,MAAM,CAACO,GAAG,EAAE,IAAI,CAAC;MACnB,CAAC,CAAC;IACJ,CAAC,CAAC;EACJ;;EAEA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,MAAMC,iBAAiBA,CAAA,EAAI;IACzB,IAAI,CAAC7E,EAAE,CAAC8E,aAAa,CAAC,CAAC;;IAEvB;IACA,IAAI,IAAI,CAAC7E,YAAY,EAAE;IACvB,MAAMJ,WAAW,CAACkF,gCAAgC,CAAC,IAAI,CAAC7E,QAAQ,EAAE,IAAI,CAACG,KAAK,CAACE,OAAO,CAAC;IACrF,MAAMd,OAAO,CAACuF,4BAA4B,CAAC,IAAI,CAAC9E,QAAQ,EAAE,IAAI,CAACG,KAAK,CAACC,QAAQ,CAAC;IAE9E,IAAI2E,WAAW;IACf,IAAIxF,OAAO,CAACyF,cAAc,EAAE;MAC1B;MACA,MAAMC,UAAU,GAAG1F,OAAO,CAACyF,cAAc,CAAC,IAAI,CAAChF,QAAQ,EAAE;QAAEuC,QAAQ,EAAE,MAAM;QAAEC,IAAI,EAAE,IAAI,CAACrC,KAAK,CAACC;MAAS,CAAC,CAAC;MACzG2E,WAAW,GAAG,MAAM,IAAI,CAAChB,mBAAmB,CAACkB,UAAU,CAAC;IAC1D,CAAC,MAAM;MACL;MACA,MAAMvC,OAAO,GAAG,MAAMnD,OAAO,CAAC2F,aAAa,CAAC,IAAI,CAAClF,QAAQ,EAAE;QAAEuC,QAAQ,EAAE,MAAM;QAAEC,IAAI,EAAE,IAAI,CAACrC,KAAK,CAACC;MAAS,CAAC,CAAC;MAC3G2E,WAAW,GAAG,MAAM,IAAI,CAACtC,YAAY,CAACC,OAAO,CAAC;IAChD;IACA;IACAtB,MAAM,CAACC,IAAI,CAAC0D,WAAW,CAACzD,OAAO,CAAC,CAAC6D,OAAO,CAACC,GAAG,IAAI;MAC9C,IAAI,CAACtF,EAAE,CAACwB,OAAO,CAAC8D,GAAG,CAAC,GAAG,IAAI/F,KAAK,CAAC0F,WAAW,CAACzD,OAAO,CAAC8D,GAAG,CAAC,CAAC;IAC5D,CAAC,CAAC;;IAEF;IACA,IAAI;MACF,IAAI,CAACtF,EAAE,CAAC8E,aAAa,CAACG,WAAW,CAACpC,IAAI,CAAC;IACzC,CAAC,CAAC,OAAOa,CAAC,EAAE;MACV,IAAI,CAAC1D,EAAE,CAAC8E,aAAa,CAAC,CAAC,EAAC;MACxB,MAAMpB,CAAC;IACT;IAEA,MAAM,IAAI,CAAC1D,EAAE,CAACuF,WAAW,CAACxE,0BAA0B,CAAC,CAAC;IACtD,IAAI,CAACf,EAAE,CAACwF,QAAQ,CAACC,aAAa,CAAC,CAAC;EAClC;;EAEA;AACF;AACA;AACA;AACA;AACA;AACA;EACE,MAAMC,iBAAiBA,CAAA,EAAI;IACzB,IAAI,CAAC1F,EAAE,CAACoC,kBAAkB,CAAC,CAAC,EAAC;IAC7B,IAAI,CAACpC,EAAE,CAACwF,QAAQ,CAACG,KAAK,GAAG,KAAK,EAAC;IAC/B,IAAI,CAAC3F,EAAE,CAACwF,QAAQ,CAACI,WAAW,CAAC,CAAC,EAAC;IAC/B,MAAM,IAAI,CAAC5F,EAAE,CAACwF,QAAQ,CAACK,KAAK,CAAClB,QAAQ,EAAC;IACtC;IACA,IAAI,CAAC3E,EAAE,CAACwB,OAAO,GAAG,CAAC,CAAC;IACpB;IACA,IAAI,CAACxB,EAAE,CAACwB,OAAO,CAAC+B,GAAG,GAAG,IAAIhE,KAAK,CAAC;MAAE8B,SAAS,EAAE,KAAK;MAAEK,MAAM,EAAE;IAAK,CAAC,CAAC;IACnE;IACA,IAAI,CAAC1B,EAAE,CAAC8F,UAAU,GAAG,CAAC,CAAC;;IAEvB;IACA,IAAI,CAAC,IAAI,CAAC9F,EAAE,CAACC,YAAY,EAAE;MACzB,MAAM,IAAI,CAACD,EAAE,CAACwF,QAAQ,CAACO,SAAS,CAAC,YAAY;QAC3C,IAAI,MAAMtG,OAAO,CAACuG,WAAW,CAAC,IAAI,CAAC9F,QAAQ,CAAC,EAAE,MAAMT,OAAO,CAACwG,WAAW,CAAC,IAAI,CAAC/F,QAAQ,CAAC;MACxF,CAAC,EAAE,IAAI,CAAC;IACV;EACF;;EAEA;AACF;AACA;AACA;AACA;AACA;AACA;EACE,aAAa6E,gCAAgCA,CAAEmB,GAAG,EAAExD,IAAI,GAAG/C,gBAAgB,EAAE;IAC3E,OAAOF,OAAO,CAACsF,gCAAgC,CAACmB,GAAG,EAAExD,IAAI,CAAC;EAC5D;AACF;;AAEA;AACAyD,MAAM,CAACC,OAAO,GAAGvG,WAAW","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}